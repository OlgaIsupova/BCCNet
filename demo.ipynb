{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BCCNet demo on MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script demonstrates BCCNet in action on classification of MNIST\n",
    "\n",
    "* first generates synthetic crowdsourced labels for MNIST. Only 50% of training data is labelled by 4 crowd members with the average reliability of 0.6\n",
    "* iterates one call of the VB_iteration function and one epoch of backpropagated updates for the parameters of a neural network\n",
    "* saves weights of the trained neural network\n",
    "* plots accuracy performance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Required import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from NNArchitecture.lenet5_mnist import cnn_for_mnist\n",
    "from SyntheticCrowdsourcing.synthetic_crowd_experts import generate_expert_labels\n",
    "from VariationalInference.VB_iteration import VB_iteration\n",
    "from utils.utils_dataset_processing import shrink_arrays\n",
    "from VariationalInference import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rseed = 1000\n",
    "np.random.seed(rseed)\n",
    "tf.set_random_seed(rseed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "crowdsourced_labelled_train_data_ratio = 0.5 # ratio of train data labelled by crowd members\n",
    "n_crowd_members = 4\n",
    "crowd_member_reliability_level = 0.6\n",
    "confusion_matrix_diagonal_prior = 1e-1\n",
    "n_epoch = 100\n",
    "batch_size = 32\n",
    "convergence_threshold = 1e-6 # convergence is measured as change in ELBO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data(path=os.getcwd() + '/mnist.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expand dimensions for images to explicitly have 1 channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.expand_dims(x_train, axis=3)\n",
    "x_test = np.expand_dims(x_test, axis=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select subsample of train data to be \"labelled\" by crowd members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_train, whole_train = shrink_arrays([x_train, y_train], crowdsourced_labelled_train_data_ratio, is_shuffle=True)\n",
    "x_labelled_train = labelled_train[0]\n",
    "y_labelled_train = labelled_train[1]\n",
    "x_train = whole_train[0]\n",
    "y_train = whole_train[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate synthetic crowdsourced labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "crowdsourced_labels = generate_expert_labels(n_experts=n_crowd_members, n_classes=n_classes, \n",
    "                                             gt_labels=y_labelled_train,\n",
    "                                             n_total_tasks=x_train.shape[0],\n",
    "                                             reliability_level=crowd_member_reliability_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up a neural network and variational parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/danilkuzin/Documents/danilka/study/github/BCCNet/NNArchitecture/lenet5_mnist.py:5: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cnn_model = cnn_for_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_param_confusion_matrices = confusion_matrix.initialise_prior(n_classes=n_classes, n_experts=n_crowd_members,\n",
    "                                                                   alpha_diag_prior=confusion_matrix_diagonal_prior)\n",
    "variational_param_confusion_matrices = np.copy(prior_param_confusion_matrices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialisation of the approximating posterior of true labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial variational inference iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_nn_output_for_vb_update = np.random.randn(x_train.shape[0], n_classes)\n",
    "\n",
    "q_t, variational_param_confusion_matrices, lower_bound = \\\n",
    "    VB_iteration(crowdsourced_labels, initial_nn_output_for_vb_update, variational_param_confusion_matrices,\n",
    "                 prior_param_confusion_matrices)\n",
    "\n",
    "old_lower_bound = lower_bound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main training cycle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up evaluation arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on predictions from neural network\n",
    "nn_training_accuracy = np.zeros((n_epoch,), dtype=np.float64)   \n",
    "# based on approximated posterior for true labels\n",
    "posterior_estimate_training_accuracy = np.zeros((n_epoch,), dtype=np.float64)  \n",
    "nn_test_accuracy = np.zeros((n_epoch,), dtype=np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0:\n",
      "\t nn training accuracy: 0.10371666666666667\n",
      "\t posterior estimate training accuracy: 0.4346833333333333\n",
      "\t nn test accuracy: 0.1068\n",
      "epoch 1:\n",
      "\t nn training accuracy: 0.109\n",
      "\t posterior estimate training accuracy: 0.44206666666666666\n",
      "\t nn test accuracy: 0.1117\n",
      "epoch 2:\n",
      "\t nn training accuracy: 0.14205\n",
      "\t posterior estimate training accuracy: 0.46176666666666666\n",
      "\t nn test accuracy: 0.1413\n",
      "epoch 3:\n",
      "\t nn training accuracy: 0.20383333333333334\n",
      "\t posterior estimate training accuracy: 0.50165\n",
      "\t nn test accuracy: 0.2043\n",
      "epoch 4:\n",
      "\t nn training accuracy: 0.6040333333333333\n",
      "\t posterior estimate training accuracy: 0.7282833333333333\n",
      "\t nn test accuracy: 0.6077\n",
      "epoch 5:\n",
      "\t nn training accuracy: 0.96025\n",
      "\t posterior estimate training accuracy: 0.9351333333333334\n",
      "\t nn test accuracy: 0.9637\n",
      "epoch 6:\n",
      "\t nn training accuracy: 0.9763\n",
      "\t posterior estimate training accuracy: 0.9558666666666666\n",
      "\t nn test accuracy: 0.976\n",
      "epoch 7:\n",
      "\t nn training accuracy: 0.9823\n",
      "\t posterior estimate training accuracy: 0.9665833333333333\n",
      "\t nn test accuracy: 0.9802\n",
      "epoch 8:\n",
      "\t nn training accuracy: 0.98645\n",
      "\t posterior estimate training accuracy: 0.9720166666666666\n",
      "\t nn test accuracy: 0.9832\n",
      "epoch 9:\n",
      "\t nn training accuracy: 0.9872333333333333\n",
      "\t posterior estimate training accuracy: 0.9741833333333333\n",
      "\t nn test accuracy: 0.9841\n",
      "epoch 10:\n",
      "\t nn training accuracy: 0.9884166666666667\n",
      "\t posterior estimate training accuracy: 0.9752833333333333\n",
      "\t nn test accuracy: 0.985\n",
      "epoch 11:\n",
      "\t nn training accuracy: 0.9881\n",
      "\t posterior estimate training accuracy: 0.9745\n",
      "\t nn test accuracy: 0.9848\n",
      "epoch 12:\n",
      "\t nn training accuracy: 0.9866666666666667\n",
      "\t posterior estimate training accuracy: 0.9729\n",
      "\t nn test accuracy: 0.9845\n",
      "epoch 13:\n",
      "\t nn training accuracy: 0.9832833333333333\n",
      "\t posterior estimate training accuracy: 0.97065\n",
      "\t nn test accuracy: 0.9832\n",
      "epoch 14:\n",
      "\t nn training accuracy: 0.9799333333333333\n",
      "\t posterior estimate training accuracy: 0.9690333333333333\n",
      "\t nn test accuracy: 0.9824\n",
      "epoch 15:\n",
      "\t nn training accuracy: 0.9750666666666666\n",
      "\t posterior estimate training accuracy: 0.9661333333333333\n",
      "\t nn test accuracy: 0.9827\n",
      "epoch 16:\n",
      "\t nn training accuracy: 0.9707166666666667\n",
      "\t posterior estimate training accuracy: 0.9637666666666667\n",
      "\t nn test accuracy: 0.9813\n",
      "epoch 17:\n",
      "\t nn training accuracy: 0.9681\n",
      "\t posterior estimate training accuracy: 0.9624666666666667\n",
      "\t nn test accuracy: 0.9813\n",
      "epoch 18:\n",
      "\t nn training accuracy: 0.9651333333333333\n",
      "\t posterior estimate training accuracy: 0.9615666666666667\n",
      "\t nn test accuracy: 0.9818\n",
      "epoch 19:\n",
      "\t nn training accuracy: 0.9630333333333333\n",
      "\t posterior estimate training accuracy: 0.9601\n",
      "\t nn test accuracy: 0.9801\n",
      "epoch 20:\n",
      "\t nn training accuracy: 0.9606\n",
      "\t posterior estimate training accuracy: 0.95845\n",
      "\t nn test accuracy: 0.9802\n",
      "epoch 21:\n",
      "\t nn training accuracy: 0.95905\n",
      "\t posterior estimate training accuracy: 0.95705\n",
      "\t nn test accuracy: 0.9792\n",
      "epoch 22:\n",
      "\t nn training accuracy: 0.9571666666666667\n",
      "\t posterior estimate training accuracy: 0.9559\n",
      "\t nn test accuracy: 0.9796\n",
      "epoch 23:\n",
      "\t nn training accuracy: 0.95605\n",
      "\t posterior estimate training accuracy: 0.95505\n",
      "\t nn test accuracy: 0.9799\n",
      "epoch 24:\n",
      "\t nn training accuracy: 0.9547833333333333\n",
      "\t posterior estimate training accuracy: 0.9540833333333333\n",
      "\t nn test accuracy: 0.9786\n",
      "epoch 25:\n",
      "\t nn training accuracy: 0.95335\n",
      "\t posterior estimate training accuracy: 0.9526666666666667\n",
      "\t nn test accuracy: 0.9799\n",
      "epoch 26:\n",
      "\t nn training accuracy: 0.95285\n",
      "\t posterior estimate training accuracy: 0.9521166666666666\n",
      "\t nn test accuracy: 0.9797\n",
      "epoch 27:\n",
      "\t nn training accuracy: 0.9521\n",
      "\t posterior estimate training accuracy: 0.9514666666666667\n",
      "\t nn test accuracy: 0.9804\n",
      "epoch 28:\n",
      "\t nn training accuracy: 0.9518333333333333\n",
      "\t posterior estimate training accuracy: 0.9515166666666667\n",
      "\t nn test accuracy: 0.9798\n",
      "epoch 29:\n",
      "\t nn training accuracy: 0.9516666666666667\n",
      "\t posterior estimate training accuracy: 0.9512833333333334\n",
      "\t nn test accuracy: 0.9801\n",
      "epoch 30:\n",
      "\t nn training accuracy: 0.9516333333333333\n",
      "\t posterior estimate training accuracy: 0.9513\n",
      "\t nn test accuracy: 0.9795\n",
      "epoch 31:\n",
      "\t nn training accuracy: 0.9513666666666667\n",
      "\t posterior estimate training accuracy: 0.9510333333333333\n",
      "\t nn test accuracy: 0.9802\n",
      "epoch 32:\n",
      "\t nn training accuracy: 0.95105\n",
      "\t posterior estimate training accuracy: 0.9507833333333333\n",
      "\t nn test accuracy: 0.9789\n",
      "epoch 33:\n",
      "\t nn training accuracy: 0.9507666666666666\n",
      "\t posterior estimate training accuracy: 0.9506166666666667\n",
      "\t nn test accuracy: 0.9786\n",
      "epoch 34:\n",
      "\t nn training accuracy: 0.9504666666666667\n",
      "\t posterior estimate training accuracy: 0.95025\n",
      "\t nn test accuracy: 0.978\n",
      "epoch 35:\n",
      "\t nn training accuracy: 0.9501333333333334\n",
      "\t posterior estimate training accuracy: 0.95\n",
      "\t nn test accuracy: 0.9773\n",
      "epoch 36:\n",
      "\t nn training accuracy: 0.9499\n",
      "\t posterior estimate training accuracy: 0.9498166666666666\n",
      "\t nn test accuracy: 0.9791\n",
      "epoch 37:\n",
      "\t nn training accuracy: 0.94975\n",
      "\t posterior estimate training accuracy: 0.9496666666666667\n",
      "\t nn test accuracy: 0.9776\n",
      "epoch 38:\n",
      "\t nn training accuracy: 0.9494833333333333\n",
      "\t posterior estimate training accuracy: 0.9494333333333334\n",
      "\t nn test accuracy: 0.9765\n",
      "epoch 39:\n",
      "\t nn training accuracy: 0.9497\n",
      "\t posterior estimate training accuracy: 0.94945\n",
      "\t nn test accuracy: 0.9792\n",
      "epoch 40:\n",
      "\t nn training accuracy: 0.9497833333333333\n",
      "\t posterior estimate training accuracy: 0.9496166666666667\n",
      "\t nn test accuracy: 0.9779\n",
      "epoch 41:\n",
      "\t nn training accuracy: 0.9495166666666667\n",
      "\t posterior estimate training accuracy: 0.94945\n",
      "\t nn test accuracy: 0.9766\n",
      "epoch 42:\n",
      "\t nn training accuracy: 0.9493\n",
      "\t posterior estimate training accuracy: 0.9491833333333334\n",
      "\t nn test accuracy: 0.9763\n",
      "epoch 43:\n",
      "\t nn training accuracy: 0.9493333333333334\n",
      "\t posterior estimate training accuracy: 0.9491833333333334\n",
      "\t nn test accuracy: 0.9748\n",
      "epoch 44:\n",
      "\t nn training accuracy: 0.94885\n",
      "\t posterior estimate training accuracy: 0.9488\n",
      "\t nn test accuracy: 0.9763\n",
      "epoch 45:\n",
      "\t nn training accuracy: 0.9486\n",
      "\t posterior estimate training accuracy: 0.94845\n",
      "\t nn test accuracy: 0.9774\n",
      "epoch 46:\n",
      "\t nn training accuracy: 0.9485333333333333\n",
      "\t posterior estimate training accuracy: 0.9484166666666667\n",
      "\t nn test accuracy: 0.9768\n",
      "epoch 47:\n",
      "\t nn training accuracy: 0.9487\n",
      "\t posterior estimate training accuracy: 0.9485333333333333\n",
      "\t nn test accuracy: 0.9762\n",
      "epoch 48:\n",
      "\t nn training accuracy: 0.9484\n",
      "\t posterior estimate training accuracy: 0.9483333333333334\n",
      "\t nn test accuracy: 0.976\n",
      "epoch 49:\n",
      "\t nn training accuracy: 0.9481\n",
      "\t posterior estimate training accuracy: 0.9481333333333334\n",
      "\t nn test accuracy: 0.9749\n",
      "epoch 50:\n",
      "\t nn training accuracy: 0.9479166666666666\n",
      "\t posterior estimate training accuracy: 0.9478833333333333\n",
      "\t nn test accuracy: 0.9781\n",
      "epoch 51:\n",
      "\t nn training accuracy: 0.9479833333333333\n",
      "\t posterior estimate training accuracy: 0.94785\n",
      "\t nn test accuracy: 0.9764\n",
      "epoch 52:\n",
      "\t nn training accuracy: 0.9482333333333334\n",
      "\t posterior estimate training accuracy: 0.9480666666666666\n",
      "\t nn test accuracy: 0.9761\n",
      "epoch 53:\n",
      "\t nn training accuracy: 0.94845\n",
      "\t posterior estimate training accuracy: 0.9482833333333334\n",
      "\t nn test accuracy: 0.9789\n",
      "epoch 54:\n",
      "\t nn training accuracy: 0.9483666666666667\n",
      "\t posterior estimate training accuracy: 0.9483333333333334\n",
      "\t nn test accuracy: 0.9781\n",
      "epoch 55:\n",
      "\t nn training accuracy: 0.9483666666666667\n",
      "\t posterior estimate training accuracy: 0.9483\n",
      "\t nn test accuracy: 0.9786\n",
      "epoch 56:\n",
      "\t nn training accuracy: 0.9489666666666666\n",
      "\t posterior estimate training accuracy: 0.9487833333333333\n",
      "\t nn test accuracy: 0.9774\n",
      "epoch 57:\n",
      "\t nn training accuracy: 0.9490166666666666\n",
      "\t posterior estimate training accuracy: 0.9489\n",
      "\t nn test accuracy: 0.9783\n",
      "epoch 58:\n",
      "\t nn training accuracy: 0.9489333333333333\n",
      "\t posterior estimate training accuracy: 0.9488833333333333\n",
      "\t nn test accuracy: 0.98\n",
      "epoch 59:\n",
      "\t nn training accuracy: 0.9489333333333333\n",
      "\t posterior estimate training accuracy: 0.9488833333333333\n",
      "\t nn test accuracy: 0.9789\n",
      "epoch 60:\n",
      "\t nn training accuracy: 0.9487333333333333\n",
      "\t posterior estimate training accuracy: 0.9486833333333333\n",
      "\t nn test accuracy: 0.9781\n",
      "epoch 61:\n",
      "\t nn training accuracy: 0.9488333333333333\n",
      "\t posterior estimate training accuracy: 0.9488166666666666\n",
      "\t nn test accuracy: 0.9792\n",
      "epoch 62:\n",
      "\t nn training accuracy: 0.94895\n",
      "\t posterior estimate training accuracy: 0.9489333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t nn test accuracy: 0.9792\n",
      "epoch 63:\n",
      "\t nn training accuracy: 0.9489666666666666\n",
      "\t posterior estimate training accuracy: 0.9489\n",
      "\t nn test accuracy: 0.9777\n",
      "epoch 64:\n",
      "\t nn training accuracy: 0.9488166666666666\n",
      "\t posterior estimate training accuracy: 0.9487\n",
      "\t nn test accuracy: 0.9746\n",
      "epoch 65:\n",
      "\t nn training accuracy: 0.9488166666666666\n",
      "\t posterior estimate training accuracy: 0.9488\n",
      "\t nn test accuracy: 0.9779\n",
      "epoch 66:\n",
      "\t nn training accuracy: 0.9485833333333333\n",
      "\t posterior estimate training accuracy: 0.9485833333333333\n",
      "\t nn test accuracy: 0.9758\n",
      "epoch 67:\n",
      "\t nn training accuracy: 0.9487666666666666\n",
      "\t posterior estimate training accuracy: 0.9487\n",
      "\t nn test accuracy: 0.9768\n",
      "epoch 68:\n",
      "\t nn training accuracy: 0.9488833333333333\n",
      "\t posterior estimate training accuracy: 0.9488333333333333\n",
      "\t nn test accuracy: 0.9792\n",
      "epoch 69:\n",
      "\t nn training accuracy: 0.9490166666666666\n",
      "\t posterior estimate training accuracy: 0.9488833333333333\n",
      "\t nn test accuracy: 0.9769\n",
      "epoch 70:\n",
      "\t nn training accuracy: 0.9490333333333333\n",
      "\t posterior estimate training accuracy: 0.9489166666666666\n",
      "\t nn test accuracy: 0.9786\n",
      "epoch 71:\n",
      "\t nn training accuracy: 0.9489166666666666\n",
      "\t posterior estimate training accuracy: 0.94885\n",
      "\t nn test accuracy: 0.9779\n",
      "epoch 72:\n",
      "\t nn training accuracy: 0.9490166666666666\n",
      "\t posterior estimate training accuracy: 0.94885\n",
      "\t nn test accuracy: 0.9783\n",
      "epoch 73:\n",
      "\t nn training accuracy: 0.9489666666666666\n",
      "\t posterior estimate training accuracy: 0.9489\n",
      "\t nn test accuracy: 0.9774\n",
      "epoch 74:\n",
      "\t nn training accuracy: 0.9491166666666667\n",
      "\t posterior estimate training accuracy: 0.94905\n",
      "\t nn test accuracy: 0.979\n",
      "epoch 75:\n",
      "\t nn training accuracy: 0.949\n",
      "\t posterior estimate training accuracy: 0.9489833333333333\n",
      "\t nn test accuracy: 0.9775\n",
      "epoch 76:\n",
      "\t nn training accuracy: 0.94905\n",
      "\t posterior estimate training accuracy: 0.9489666666666666\n",
      "\t nn test accuracy: 0.9769\n",
      "epoch 77:\n",
      "\t nn training accuracy: 0.94895\n",
      "\t posterior estimate training accuracy: 0.9489166666666666\n",
      "\t nn test accuracy: 0.9782\n",
      "epoch 78:\n",
      "\t nn training accuracy: 0.94905\n",
      "\t posterior estimate training accuracy: 0.949\n",
      "\t nn test accuracy: 0.9779\n",
      "epoch 79:\n",
      "\t nn training accuracy: 0.9490333333333333\n",
      "\t posterior estimate training accuracy: 0.94905\n",
      "\t nn test accuracy: 0.9763\n",
      "epoch 80:\n",
      "\t nn training accuracy: 0.9489\n",
      "\t posterior estimate training accuracy: 0.9489166666666666\n",
      "\t nn test accuracy: 0.9765\n",
      "epoch 81:\n",
      "\t nn training accuracy: 0.9487\n",
      "\t posterior estimate training accuracy: 0.9487166666666667\n",
      "\t nn test accuracy: 0.9762\n",
      "epoch 82:\n",
      "\t nn training accuracy: 0.94885\n",
      "\t posterior estimate training accuracy: 0.94885\n",
      "\t nn test accuracy: 0.9789\n",
      "epoch 83:\n",
      "\t nn training accuracy: 0.94885\n",
      "\t posterior estimate training accuracy: 0.9488166666666666\n",
      "\t nn test accuracy: 0.9757\n",
      "epoch 84:\n",
      "\t nn training accuracy: 0.9487166666666667\n",
      "\t posterior estimate training accuracy: 0.9487\n",
      "\t nn test accuracy: 0.9754\n",
      "epoch 85:\n",
      "\t nn training accuracy: 0.9488\n",
      "\t posterior estimate training accuracy: 0.9487833333333333\n",
      "\t nn test accuracy: 0.9759\n",
      "epoch 86:\n",
      "\t nn training accuracy: 0.94865\n",
      "\t posterior estimate training accuracy: 0.94865\n",
      "\t nn test accuracy: 0.9757\n",
      "epoch 87:\n",
      "\t nn training accuracy: 0.9487166666666667\n",
      "\t posterior estimate training accuracy: 0.9486833333333333\n",
      "\t nn test accuracy: 0.9767\n",
      "epoch 88:\n",
      "\t nn training accuracy: 0.9487666666666666\n",
      "\t posterior estimate training accuracy: 0.9486833333333333\n",
      "\t nn test accuracy: 0.9774\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epoch):\n",
    "    print(f'epoch {epoch}:')\n",
    "\n",
    "    # update of parameters of the neural network\n",
    "    cnn_model.fit(x_train, q_t, epochs=1, shuffle=True, batch_size=batch_size, verbose=0)\n",
    "\n",
    "    # update of approximating posterior for the true labels and confusion matrices\n",
    "    # get current predictions from a neural network\n",
    "    nn_output_for_vb_update = cnn_model.predict(x_train)\n",
    "    # for numerical stability\n",
    "    nn_output_for_vb_update = nn_output_for_vb_update - \\\n",
    "        np.tile(np.expand_dims(np.max(nn_output_for_vb_update, axis=1), axis=1), \n",
    "                (1, nn_output_for_vb_update.shape[1]))\n",
    "\n",
    "    q_t, variational_param_confusion_matrices, lower_bound = \\\n",
    "        VB_iteration(crowdsourced_labels, nn_output_for_vb_update, variational_param_confusion_matrices,\n",
    "                     prior_param_confusion_matrices)\n",
    "\n",
    "    # evaluation\n",
    "    nn_training_accuracy[epoch] = np.mean(np.argmax(nn_output_for_vb_update, axis=1) == y_train)\n",
    "    print(f'\\t nn training accuracy: {nn_training_accuracy[epoch]}')\n",
    "\n",
    "    posterior_estimate_training_accuracy[epoch] = np.mean(np.argmax(q_t, axis=1) == y_train)\n",
    "    print(f'\\t posterior estimate training accuracy: {posterior_estimate_training_accuracy[epoch]}')\n",
    "\n",
    "    nn_test_prediction = cnn_model.predict(x_test)\n",
    "    nn_test_accuracy[epoch] = np.mean(np.argmax(nn_test_prediction, axis=1) == y_test)\n",
    "    print(f'\\t nn test accuracy: {nn_test_accuracy[epoch]}')\n",
    "\n",
    "    # check convergence\n",
    "    if np.abs((lower_bound - old_lower_bound) / old_lower_bound) < convergence_threshold:\n",
    "        break\n",
    "\n",
    "    old_lower_bound = lower_bound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x103e782b0>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n"
     ]
    }
   ],
   "source": [
    "cnn_model.save_weights(os.getcwd() + '/trained_weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot accuracy performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(epoch), nn_training_accuracy[:epoch], label='nn train')\n",
    "plt.plot(range(epoch), posterior_estimate_training_accuracy[:epoch], label='posterior train')\n",
    "plt.plot(range(epoch), nn_test_accuracy[:epoch], label='nn test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
